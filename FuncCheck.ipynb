{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets, metrics, cross_validation\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "data_train = pd.read_csv('tweet.csv', header=None)\n",
    "data_train.columns = ['Sentiment','Text']\n",
    "data_train = data_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data_train['Text'])\n",
    "y = np.array(data_train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(C=1.0, penalty='l2')\n",
    "lg.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74063265552000646"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = vectorizer.transform(X_test)\n",
    "pred = lg.predict(test)\n",
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob = lg.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24207804,  0.75792196],\n",
       "       [ 0.20301308,  0.79698692],\n",
       "       [ 0.18476213,  0.81523787],\n",
       "       ..., \n",
       "       [ 0.26482961,  0.73517039],\n",
       "       [ 0.13427453,  0.86572547],\n",
       "       [ 0.76098986,  0.23901014]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7086, 27890, 10308, 51090, 34581, 65336, 51960, 10194,  8515,\n",
       "       61063, 60034, 68151, 59209, 50805,  2757, 57568, 24595,  6444,\n",
       "       38175, 65188, 22111, 69852, 60733, 68347, 63964, 53467, 41007,\n",
       "       12895, 74613, 28999,  3302, 59260,  3341, 35905, 23242, 60486,\n",
       "        6358, 46180,  9777, 30879, 24216, 55542, 56828, 50659,  8091,\n",
       "       42026, 15183,  2956, 35820, 11392,  2024, 24765, 19438, 56116,\n",
       "       11105, 37921, 16826, 32084, 39263,  4763, 41970, 47951, 13831,\n",
       "       14000, 21811, 51158, 39386, 37327, 30638, 20374, 67112, 73341,\n",
       "       34825,   415, 55079, 54944, 13930, 74086, 59063, 29517, 12237,\n",
       "       13378, 18723, 55495,  1150, 19461, 65145,  1030, 48696, 51545,\n",
       "       30173, 31983, 40282,  7918, 59081, 56796, 56892, 73156, 27907, 57650], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_entropies = stats.distributions.entropy(prob.T)\n",
    "uncertainty_index = uncertainty_index = np.argsort(pred_entropies)[-100:]\n",
    "uncertainty_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_X = vectorizer.fit_transform(data_train['Text'])\n",
    "X = tfidf_X.toarray()\n",
    "y = np.array(data_train['Sentiment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
